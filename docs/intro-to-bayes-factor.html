<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title> Chapter 3 Intro to Bayes Factor | Bayes Factor</title>
  <meta name="description" content=" Chapter 3 Intro to Bayes Factor | Bayes Factor" />
  <meta name="generator" content="bookdown 0.21.6 and GitBook 2.6.7" />

  <meta property="og:title" content=" Chapter 3 Intro to Bayes Factor | Bayes Factor" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="kateliberko/MathStatBayesFactor" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content=" Chapter 3 Intro to Bayes Factor | Bayes Factor" />
  
  
  

<meta name="author" content="Mathematical Statistics Capstone written by Kate Liberko and Isabella Light" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="background.html"/>
<link rel="next" href="example-problemsexercises.html"/>
<script src="libs/header-attrs-2.6/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>




</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="motivation-of-topic.html"><a href="motivation-of-topic.html"><i class="fa fa-check"></i><b>1</b> Motivation of Topic</a></li>
<li class="chapter" data-level="2" data-path="background.html"><a href="background.html"><i class="fa fa-check"></i><b>2</b> Background</a>
<ul>
<li class="chapter" data-level="2.1" data-path="background.html"><a href="background.html#bayesian-vs-frequentist-statistics"><i class="fa fa-check"></i><b>2.1</b> Bayesian vs Frequentist Statistics</a></li>
<li class="chapter" data-level="2.2" data-path="background.html"><a href="background.html#hypothesis-testing"><i class="fa fa-check"></i><b>2.2</b> Hypothesis Testing</a></li>
<li class="chapter" data-level="2.3" data-path="background.html"><a href="background.html#the-p-value"><i class="fa fa-check"></i><b>2.3</b> The P-value</a></li>
<li class="chapter" data-level="2.4" data-path="background.html"><a href="background.html#prior-odds"><i class="fa fa-check"></i><b>2.4</b> Prior Odds</a></li>
<li class="chapter" data-level="2.5" data-path="background.html"><a href="background.html#posterior-odds"><i class="fa fa-check"></i><b>2.5</b> Posterior Odds</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="intro-to-bayes-factor.html"><a href="intro-to-bayes-factor.html"><i class="fa fa-check"></i><b>3</b> Intro to Bayes Factor</a>
<ul>
<li class="chapter" data-level="3.1" data-path="intro-to-bayes-factor.html"><a href="intro-to-bayes-factor.html#a-bayes-walkthrough"><i class="fa fa-check"></i><b>3.1</b> A Bayes Walkthrough</a></li>
<li class="chapter" data-level="3.2" data-path="intro-to-bayes-factor.html"><a href="intro-to-bayes-factor.html#interpreting-the-ratio"><i class="fa fa-check"></i><b>3.2</b> Interpreting The Ratio</a></li>
<li class="chapter" data-level="3.3" data-path="intro-to-bayes-factor.html"><a href="intro-to-bayes-factor.html#likelihood-approach-to-find-a-bayes-factor"><i class="fa fa-check"></i><b>3.3</b> Likelihood Approach to find a Bayes Factor</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="intro-to-bayes-factor.html"><a href="intro-to-bayes-factor.html#what-is-likelihood"><i class="fa fa-check"></i><b>3.3.1</b> What is Likelihood?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="example-problemsexercises.html"><a href="example-problemsexercises.html"><i class="fa fa-check"></i><b>4</b> Example Problems/Exercises</a>
<ul>
<li class="chapter" data-level="4.1" data-path="example-problemsexercises.html"><a href="example-problemsexercises.html#using-posteriors-and-priors"><i class="fa fa-check"></i><b>4.1</b> Using Posteriors and Priors</a></li>
<li class="chapter" data-level="4.2" data-path="example-problemsexercises.html"><a href="example-problemsexercises.html#using-likelihoods"><i class="fa fa-check"></i><b>4.2</b> Using Likelihoods</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="real-world-applications.html"><a href="real-world-applications.html"><i class="fa fa-check"></i><b>5</b> Real World Applications</a>
<ul>
<li class="chapter" data-level="5.1" data-path="real-world-applications.html"><a href="real-world-applications.html#hot-hands"><i class="fa fa-check"></i><b>5.1</b> Hot Hands</a></li>
<li class="chapter" data-level="5.2" data-path="real-world-applications.html"><a href="real-world-applications.html#ozone-exceedances"><i class="fa fa-check"></i><b>5.2</b> Ozone Exceedances</a></li>
<li class="chapter" data-level="5.3" data-path="real-world-applications.html"><a href="real-world-applications.html#formation-of-mutations-in-e.coli-dna"><i class="fa fa-check"></i><b>5.3</b> Formation of Mutations in E.Coli DNA</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="critiques-of-bayes-factor-approach.html"><a href="critiques-of-bayes-factor-approach.html"><i class="fa fa-check"></i><b>6</b> Critiques of Bayes Factor Approach</a></li>
<li class="chapter" data-level="7" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>7</b> References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Bayes Factor</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="intro-to-bayes-factor" class="section level1" number="3">
<h1><span class="header-section-number"> Chapter 3</span> Intro to Bayes Factor</h1>
<p>When looking at solving a problem by comparing two models, we can take a frequentist approach or a Bayesian approach. If we are trying to decide if it’s worth it to get this new fertilizer for our plants we will need to gather some data. A frequentist would conduct an experiment and would look at the data and the p-value to make a decision. After collecting data using the new fertilizer, we see that our plants’ health has increased. The p-value would be the probability of seeing this observed increase in plants’ health assuming that the null hypothesis (that the fertilizer has no effect) is true. In this case they are only taking into account the results of their experiment. A Bayesian would also conduct an experiment but in addition would consider their prior beliefs. Together the prior beliefs and the data will help them reach a more accurate evaluation of the plants’ health; the posterior belief. A Bayes Factor, the ratio of the posterior odds to prior odds, will inform them which hypothesis is more likely under the data. Each time that new data is observed, the initial posterior belief will become the new prior belief. Using this, Bayesians can continue to incorporate new data to keep their beliefs and Bayes Factor up to date. For these reasons, we want to use a Bayesian approach for our problem.</p>
<p><img src="pvsbf.png" width="460" style="display: block; margin: auto;" /></p>
<div id="a-bayes-walkthrough" class="section level2" number="3.1">
<h2><span class="header-section-number">3.1</span> A Bayes Walkthrough</h2>
<p>Bayes Factor is a Bayesian alternative to classical hypothesis testing. It is used to compare two statistical models (e.g. <span class="math inline">\(H_0\)</span> to <span class="math inline">\(H_1\)</span>) often displayed as a likelihood ratio between the two. It is useful because we are able to update the ratio as new information is gathered which cannot be done under frequentist hypothesis methods. <span class="math inline">\(\\\)</span></p>
<p><span class="math display">\[
\begin{aligned}
\textit{ Likelihood }H_k &amp; = \frac{\textit{ Posterior }H_k}{\textit{ Prior }H_k}\\
\\
\textit{Bayes Factor } &amp; = \frac{\textit{ Likelihood }H_1}{\textit{ Likelihood }H_0}\\
\\
&amp; = \frac{\frac{\textit{ Posterior }H_1}{\textit{ Prior }H_1}}{\frac{\textit{ Posterior }H_0}{\textit{ Prior }H_0}}\\
\\
&amp; = \frac{\textit{ Posterior }H_1}{\textit{ Prior }H_1} \cdot \frac{\textit{ Prior }H_0}{\textit{ Posterior }H_0}\\
\\
&amp; = \frac{\textit{ Posterior }H_1}{\textit{ Posterior }H_0} \cdot \frac{\textit{ Prior }H_0}{\textit{ Prior }H_1}\\ 
\\
&amp; = \frac{P(H_1|\textit{ data})}{P(H_0|\textit{ data})} \cdot \frac{P(H_0)}{P(H_1)}\\
\\
&amp; = \textit{ Posterior Odds} \cdot \frac{1}{\textit{Prior Odds}}\\
\\
\textit{Bayes Factor } &amp; = \frac{\textit{ Posterior Odds}}{\textit{Prior Odds}}
\end{aligned}
\]</span>
Now that we have some background and some useful equations we can start using this to solve our fertilizer question. We are trying to decide if it’s worth it to get this new fertilizer for our plants. Let’s define our null hypothesis as the event that the fertilizer has no effect on our plants.<span class="math inline">\(\\\)</span></p>
<p><span class="math display">\[
\begin{aligned}
H_0 =\textit{ Fertilizer has no effect} \\
\end{aligned}
\]</span></p>
<p>Our alternative hypothesis would be that the fertilizer has a good effect on our plants (this is a one-sided alternative hypothesis).<span class="math inline">\(\\\)</span></p>
<p><span class="math display">\[
\begin{aligned}
H_1 =\textit{Fertilizer has a good effect} \\
\end{aligned}
\]</span></p>
<p>Now let’s state our beliefs; these will be our priors for our hypothesis. Maybe we don’t have that much faith in the fertilizer, so we believe there is a <span class="math inline">\(60\%\)</span> chance it doesn’t have an effect on our plants and only a <span class="math inline">\(40\%\)</span> chance it does have an effect on our plants.<span class="math inline">\(\\\)</span></p>
<p><span class="math display">\[
\begin{aligned}\textit{ Prior }H_0  = 0.6 \\
\textit{ Prior }H_1 = 0.4 \\
\end{aligned}
\]</span>
We start our experiment by measuring our plants’ health before adding any fertilizer. Since we are a botanist after-all, we can measure our plants’ photosynthesis process, leaf greenness, and oxygen production. These stats will make up our data which we will call plant stats. These will be used to update our prior beliefs into posterior beliefs after the experiment. After weeks of using the fertilizer, we measure our plant stats again, and using this data, we can now define our posterior beliefs. Almost all of our plants are doing better. Wow, maybe this fertilizer really works! We now believe that the probability of the fertilizer not working is <span class="math inline">\(20\%\)</span>, and the probability of it working is <span class="math inline">\(80\%\)</span>.<span class="math inline">\(\\\)</span></p>
<p><span class="math display">\[
\begin{aligned}\textit{Posterior }H_0 = P(H_0 | \textit{ plant stats}) = 0.2 \\
\textit{Posterior }H_1 = P(H_1 | \textit{ plant stats}) = 0.8 \\
\end{aligned}
\]</span>
Now we can use our data to calculate a Bayes Factor by plugging it into formula (1) from above:
<span class="math display">\[
\begin{aligned}
\textit{Bayes Factor } &amp; = \frac{P(H_1| \textit{ plant stats})}{P(H_0|\textit{ plant stats})} \cdot \frac{P(H_0)}{P(H_1)}\\
&amp; = \frac{0.8}{0.2} \cdot \frac{0.6}{0.4}\\
&amp; = 6
\end{aligned}
\]</span>
A Bayes Factor of 6 means the alternative is 6 times more likely than the null. But what does this mean…</p>
</div>
<div id="interpreting-the-ratio" class="section level2" number="3.2">
<h2><span class="header-section-number">3.2</span> Interpreting The Ratio</h2>
<p>A great thing about a Bayes Factor is that there is no threshold or value on which to accept or deny anything. It’s up to whoever is using the Bayes to decide what the value means to them.<span class="math inline">\(\\\)</span>
<span class="math inline">\(\\\)</span>
For example now that you know that the new fertilizer is 6 times more effective than not using fertilizer, would you invest in the fertilizer? That is up to you to decide based on your own situation. Given that you are an expert botanist and your plants are already beautiful, healthy, and thriving, even if this new fertilizer is 6 times more effective, this number may not be significant enough for you to change your routine when you have no problems as is. Let’s say your friend however enjoys visiting your house because of all the beautiful plants and has decided to start their own botanical garden. As an amateur botanist, your friend has been having trouble keeping their plants healthy and half of them have died already. They might have a different reaction to the same information that the fertilizer is 6 times more effective. Given that they have not been very successful in growing a botanical garden, the fertilizer could be a game changer for their journey of raising plants. <span class="math inline">\(\\\)</span>
<span class="math inline">\(\\\)</span>
In general if the Bayes Factor (set up as <span class="math inline">\(\frac{LikelihoodH_1}{Likelihood H_0}\)</span>) is greater than one, this means the alternative hypothesis is more likely than the null hypothesis by that factor. If it is less than one, that means the null hypothesis is more likely than the alternative. In the latter we can flip the ratio to get the factor by which the null is more likely than the alternative. In the case that a Bayes Factor is one, this indicates that both models are equally likely.</p>
</div>
<div id="likelihood-approach-to-find-a-bayes-factor" class="section level2" number="3.3">
<h2><span class="header-section-number">3.3</span> Likelihood Approach to find a Bayes Factor</h2>
<p>In our above example we used simple values for our posterior and priors to get a Bayes Factor. But as you may have noticed the Bayes Factor can also be found using likelihood equations. A Bayes Factor is a weighted average likelihood ratio based on the prior distribution specified for the hypotheses. Since Bayes Factors are an extension of likelihood ratios, lets learn a little about likelihoods and their ratios!<span class="math inline">\(\\\)</span>
<span class="math inline">\(\\\)</span>
<span class="math inline">\(\underbrace{\dfrac{p(H_{0}|E,\textit{D})}{p(H_{1}|E,\textit{D})}}_{\text{Posterior Odds}}= \underbrace{\dfrac{p(E|H_{0},\textit{D})}{p(E|H_{1},\textit{D})}}_{\text{Likelihood Ratio}} \cdot \underbrace{\dfrac{p(H_{0}|\textit{D})}{p(H_{1}|\textit{D} )}}_{\text{Prior Odds}}\)</span>
<span class="math inline">\(\\\)</span> In this equation we see the likelihood ratio multiplied by the prior odds is equal to the posterior odds. If we divide both sides of the equation by the prior odds we get posterior odds divided by the prior odds are equal to the likelihood ratio. This means the Bayes Factor is the same as the likelihood ratio. <span class="math inline">\(\\\)</span>
When the hypotheses are simple, say <span class="math inline">\(H_0 = 5\)</span>, and <span class="math inline">\(H_1 = 6\)</span>, we can find the Bayes Factor by finding the posterior odds and dividing that by the prior odds as done in the plant example above. However, this method will not work if our hypotheses are a range of numbers, say <span class="math inline">\(H_0 \leq 5\)</span> and <span class="math inline">\(H_1 \geq 5\)</span>. In this case, we must integrate in order to find all possibilities of the hypotheses. We will use equation:</p>
<p><span class="math display">\[
\begin{aligned} 
  P(D|H_k) = \int_0^1 P(D| \theta_k, H_k) \cdot \pi(\theta_k | H_k) d \theta
\end{aligned} 
\]</span>
Where <span class="math inline">\(P(D|H_k)\)</span> is the integrated likelihood<span class="math inline">\(\\\)</span>
<span class="math inline">\(P(D| \theta_k, H_k)\)</span> is the probability density<span class="math inline">\(\\\)</span>
<span class="math inline">\(\pi(\theta_k | H_k)\)</span> is the prior density (<span class="math inline">\(\pi\)</span> as a function), and<span class="math inline">\(\\\)</span>
<span class="math inline">\(D\)</span> as the observed data<span class="math inline">\(\\\)</span>
<span class="math inline">\(\\\)</span>
Finding <span class="math inline">\(P(D | H_0)\)</span> and <span class="math inline">\(P(D | H_1)\)</span> by using equation (2), we can find the two likelihood equations and then take the ratio of these to calculate a Bayes Factor. The Bayes Factor is equal to the likelihood ratio.</p>
<div id="what-is-likelihood" class="section level3" number="3.3.1">
<h3><span class="header-section-number">3.3.1</span> What is Likelihood?</h3>
<p>A likelihood equation measures how well a statistical model fits a sample of data for different values of unknown parameters. Likelihood is proportional to a probability; it is not a probability itself. For example, the likelihood of a hypothesis given data is proportional to the probability of that data given the hypothesis is true multiplied by any positive constant: <span class="math inline">\(L(H|D) \propto P(D|H)K\)</span>. A big difference between likelihood and probability is the interpretation of what is what can vary. For conditional probabilities, the hypothesis is fixed while the data varies: <span class="math inline">\(P(D|H)\)</span>. Likelihood equations however, predict the likelihood of a hypothesis occurring conditioned on fixed data: <span class="math inline">\(L(H|D)\)</span>. <span class="math inline">\(\\\)</span></p>
<p>The Law of Likelihood states that “within the framework of a statistical model, a particular set of data supports one statistical hypothesis better than another if the likelihood of the first hypothesis, on the data, exceeds the likelihood of the second hypothesis” (Etz).
The value of a single likelihood is meaningless; only in comparing likelihoods, as we do for a Bayes Factor, do we find meaning.</p>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="background.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="example-problemsexercises.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "chapter",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
